
## 深度学习
1981 年的诺贝尔医学奖, DavidHubel 和Torsten Wiesel. 发现当瞳孔发现了眼前的物体的边缘，而且这个边缘指向某个方向时，这种神经元细胞就会活跃。

这个发现激发了人们对于神经系统的进一步思考。神经-中枢-大脑的工作过程，或许是一个不断迭代、不断抽象的过程。

这里的关键词有两个，一个是抽象，一个是迭代。从原始信号，做低级抽象，逐渐向高级抽象迭代。人类的逻辑思维，经常使用高度抽象的概念。

这个生理学的发现，促成了深度学习, 也就是多层神经元网络, 在四十年后的突破性发展。

## TensorFlow
使用 TensorFlow, 你必须明白 TensorFlow:

- 使用图 (graph) 来表示计算任务.
- 在被称之为 `会话 (Session)` 的上下文 (context) 中执行图.
- 使用 tensor 表示数据.
- 通过 `变量 (Variable)` 维护状态.
- 使用 feed 和 fetch 可以为任意的操作(arbitrary operation) 赋值或者从其中获取数据.

TensorFlow 是一个编程系统, 使用图来表示计算任务. 图中的节点被称之为 _op_ (operation 的缩写). 一个 op 获得 0 个或多个 `Tensor`, 执行计算, 产生 0 个或多个 `Tensor`. 每个 Tensor 是一个类型化的多维数组. 例如, 你可以将一小组图像集表示为一个四维浮点数数组, 这四个维度分别是 `[batch, height, width, channels]`.

TensorFlow 程序通常被组织成一个构建阶段和一个执行阶段. 在构建阶段, op 的执行步骤 被描述成一个图. 在执行阶段, 使用会话执行执行图中的 op.

## tensorflow和labkit相同的设计思想

算法和硬件的发展, 使得深度学习有了用武之地. 现在应该会有一个深度学习化的过程. 但是, 深度学习本身并不会有(也不好说, 参与的人多, 调用的资源多) 大的进步. 

小规模的算法进行实验, 一旦训练成功, 就可以大规模的扩展. 


tensorflow使用的思想和labkit一样. 甚至运行方式都一样. 

都有一个设计阶段和设计表示, 然后必须执行它才可以运行. 

都有一个session和上下文. 一个图存在在一个上下文环境中. 

执行阶段, 可以被大规模并行的可扩展的执行. 

无论思想, 逻辑, 流程和结构都是一样的. 

labkit表示接口是yaml, tensor表示接口是python对象. yaml更适合普通人, python对象更适合程序员. 

学好用好labkit可以帮助入门TensorFlow
